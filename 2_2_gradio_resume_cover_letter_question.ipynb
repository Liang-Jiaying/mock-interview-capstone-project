{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O7uN95EyvDPq",
        "aVE23dUnb2A0",
        "eqI3Ka8yb6Xv",
        "lQcnJEIHb_pB",
        "J3m6fvEcps3d"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"Blue\">Abstract</font>\n",
        "\n",
        "In this notebook, we delve in using [Gradio](https://www.gradio.app/) to let people interact with the gradio version of app.\n",
        "\n",
        "**<font color=\"red\">Our goal</font>** is to explore how to use Gradio and how to make our model work in gradio.  \n",
        "\n",
        "We used following knowledge:  \n",
        "Useful links:\n",
        "1. [Gradio Playground](https://www.gradio.app/playground)\n",
        "2. [Gradio Docs](https://www.gradio.app/docs/interface)"
      ],
      "metadata": {
        "id": "H_ec5RQEu3yU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQDQBIguub4K",
        "outputId": "0328b96e-e98b-429b-db3e-2390b8c4cd94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.5.0-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.3 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=51a68a751bce1dd1c1633b15bc4f18364b36255b27349568582148bece2c3422\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.5.0 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 orjson-3.9.10 pydantic-2.5.1 pydantic-core-2.14.3 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install transformers\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "vN-OjXHW-ngT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup packages and API key"
      ],
      "metadata": {
        "id": "NP3lGANUedyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download required packages to Colab\n",
        "\n",
        "!pip install -q langchain\n",
        "!pip install -q openai\n",
        "!pip install -q chromadb\n",
        "!pip install -q tiktoken\n",
        "!pip install -q duckduckgo-search\n",
        "!pip install textract\n",
        "\n",
        "# 2. Import packages\n",
        "\n",
        "import gradio\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, RetrievalQA\n",
        "from langchain import ConversationChain\n",
        "from langchain.agents import load_tools, initialize_agent, AgentType\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "import textract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hdaI2hDNYfLb",
        "outputId": "df96dd3c-10d5-4a5b-8cba-955608d87323"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.8/496.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting argcomplete~=1.10.0 (from textract)\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract)\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract)\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract)\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.12.0 (from textract)\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.2)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=7b877b9076e08007ce8c27a4acb8c60ce3f568e75da6afc96f19cd759a3f97cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6184 sha256=a293bf12588c21eade259b4c030a3fd28ed9ab87544d883c8c26f33048dc3614\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=1630f9f8b11b49ff58e7a7e2659ccbfe70664fc3a97e3144930ab2b2c7789d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "pydrive2 1.6.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "yfinance 0.2.31 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.1.9 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.19.0 python-pptx-0.6.23 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Setup OpenAI API key\n",
        "\n",
        "# openai_api_key = getpass()\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9jZqQhgYLDr",
        "outputId": "a0f4f602-76fb-495c-82a4-a82e9f44df5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tab 1: API"
      ],
      "metadata": {
        "id": "rZ6jJlLg-zOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define get_api function"
      ],
      "metadata": {
        "id": "a5TwdvC4H_r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define get_api to pass OpenAI API key for calling models\n",
        "\n",
        "def get_api(openai_api_key):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "    return \"Key Received!\""
      ],
      "metadata": {
        "id": "qALam48gT6ya"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gradio interface"
      ],
      "metadata": {
        "id": "qjN9qqnkICVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_tab = gr.Interface(\n",
        "    fn = get_api,\n",
        "    inputs = [gr.Textbox(label=\"OpenAI API Key*\",\n",
        "                         placeholder=\"Paste you OpenAI API key here ...\", type=\"password\")\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Message\"))"
      ],
      "metadata": {
        "id": "vl72zXR6AFik"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tab 2: Resume Review"
      ],
      "metadata": {
        "id": "jWmLL2Qo-3Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define resume_review function"
      ],
      "metadata": {
        "id": "1DFFQOtCevOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_review_template = \"\"\"\n",
        "You are interviewing {company_name}, {role_title} role with a {interviewer_role}.\n",
        "This is your resume {resume}. Please review the resume, job description, and company information below.\n",
        "Give point by point feedback with rationale and suggested edits. Also, giving your examples based on your editing suggestions.\n",
        "(optional: Here is the job description: {role_description})\n",
        "(optional: Here is a description of the company: {company_description})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JvSf3-Sd2qaT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_review(comp_name, job_title, interviewer_title,\n",
        "                  comp_info=\"\", job_des=\"\", interviewer_url=\"\",\n",
        "                  your_resume=\"\"):\n",
        "\n",
        "  #### Step 1: Create prompt ####\n",
        "  # 1. Define variables in prompt\n",
        "  input_var = [\"interviewer_role\", \"company_name\", \"resume\", \"role_title\", \"role_description\", \"company_description\"]\n",
        "\n",
        "  # 2. Define prompt template\n",
        "  template = resume_review_template\n",
        "\n",
        "  # 3. Create prompt template\n",
        "  prompt = PromptTemplate(\n",
        "    input_variables = input_var,\n",
        "    template = template\n",
        "  )\n",
        "  ###############################\n",
        "\n",
        "  #### Step 2: Read resume PDF to text ####\n",
        "  extracted_resume = textract.process(your_resume.name, method='pdfminer')\n",
        "  #########################################\n",
        "\n",
        "  #### Step 3: Format prompt with user input ####\n",
        "  new_prompt = prompt.format(interviewer_role=interviewer_title,\n",
        "                            company_name=comp_name,\n",
        "                            resume=extracted_resume,\n",
        "                            role_title=job_title,\n",
        "                            role_description=job_des,\n",
        "                            company_description=comp_info)\n",
        "  ###############################################\n",
        "\n",
        "  #### Step4: Use chat model to answer the prompt ####\n",
        "  chat = ChatOpenAI(model_name = \"gpt-4\")\n",
        "  result = chat([HumanMessage(content=new_prompt)])\n",
        "  ####################################################\n",
        "\n",
        "  return result.content"
      ],
      "metadata": {
        "id": "illWu24zu2j7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gradio interface"
      ],
      "metadata": {
        "id": "cKCn04abFsa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_review_tab = gr.Interface(\n",
        "    fn = resume_review,\n",
        "    inputs = [gr.Textbox(label=\"Company Name*\"),\n",
        "              gr.Textbox(label=\"Job Title*\",\n",
        "                         placeholder=\"The job title you are going to apply goes here ...\"),\n",
        "              gr.Dropdown([\"Job Recruiter\", \"HR Manager\", \"Hiring Manager\", \"Executives\", \"Potential Coworkers\"],\n",
        "                          label=\"Who do you want to interview with?*\"),\n",
        "              gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                         placeholder=\"Sepcial information about this company you want to include\"),\n",
        "              gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                         placeholder=\"Paste the job description here ...\"),\n",
        "              gr.Textbox(label=\"Interviewer's LinkedIn URL (Optional)\",\n",
        "                         placeholder=\"Paste the URL here ...\"),\n",
        "              gr.File(file_types=[\".pdf\"])\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Feedbacks\", lines=50)\n",
        ")"
      ],
      "metadata": {
        "id": "GUpqBLnru2dc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tab 3: Cover Letter"
      ],
      "metadata": {
        "id": "egSYVzLl-70E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define cover_letter function"
      ],
      "metadata": {
        "id": "qOJ7QHaG2JAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter_template = \"\"\"\n",
        "As an experienced career coach, you help students improve their skills in\n",
        "writing a cover letter to get job interviews.  Please help this student write a\n",
        "cover letter template for {role_title} at {company_name}.\n",
        "\n",
        "Here is the student's resume:\n",
        "{resume}\n",
        "\n",
        "Here are the job description and company background that you might want to consider:\n",
        "Job Description: {role_description}\n",
        "Company Background: {company_description}\n",
        "\n",
        "Here is the outline for how to creat a cover letter template:\n",
        "Develop a Cover Letter Template\n",
        "1. Create Adaptable Template\n",
        "a. Basic Structure: Establish a clear and concise structure with an introduction, body, and conclusion.\n",
        "b. Personalize the Opening: Prepare a flexible opening that can be customized to address the specific hiring manager or team.\n",
        "c. Leave Space for Role-Specific Details: Design sections that can be easily modified to reflect the specific job and company.\n",
        "2. Incorporate Key Skills and Experiences\n",
        "a. Highlight Transferable Skills: Emphasize skills that are valuable across various roles and industries.\n",
        "b. Include Achievements: Add sections to incorporate specific accomplishments relevant to the job.\n",
        "c. Make It Result-Oriented: Focus on how your skills and experiences can benefit the potential employer.\n",
        "3. Ensure Easy Customization for Specific Roles\n",
        "a. Use Modifiable Sections: Create parts of the letter that can be easily changed for different job applications.\n",
        "b. Align with Job Description: Set up placeholders to insert keywords and requirements from the job description.\n",
        "c. Tailor to Company Culture: Prepare a segment to adapt based on the company’s culture and values as described on their website or social media.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Woj275nu2H0n"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cover_letter(comp_name, job_title, comp_info=\"\", job_des=\"\", your_resume=\"\"):\n",
        "\n",
        "  #### Step 1: Create prompt ####\n",
        "  # 1. Define variables in prompt\n",
        "  input_var = [\"role_title\", \"company_name\", \"resume\", \"role_description\",  \"company_description\"]\n",
        "\n",
        "  # 2. Define prompt template\n",
        "  template = cover_letter_template\n",
        "\n",
        "  # 3. Create prompt template\n",
        "  prompt = PromptTemplate(\n",
        "    input_variables = input_var,\n",
        "    template = template\n",
        "  )\n",
        "  ###############################\n",
        "\n",
        "  #### Step 2: Read resume PDF to text ####\n",
        "  extracted_resume = textract.process(your_resume.name, method='pdfminer')\n",
        "  #########################################\n",
        "\n",
        "  #### Step 3: Format prompt with user input ####\n",
        "  new_prompt = prompt.format(role_title=job_title,\n",
        "                             company_name=comp_name,\n",
        "                             resume=extracted_resume,\n",
        "                             role_description=job_des,\n",
        "                             company_description=comp_info)\n",
        "  ###############################################\n",
        "\n",
        "  #### Step4: Use chat model to answer the prompt ####\n",
        "  chat = ChatOpenAI(model_name = \"gpt-4\")\n",
        "  result = chat([HumanMessage(content=new_prompt)])\n",
        "  ####################################################\n",
        "\n",
        "  return result.content"
      ],
      "metadata": {
        "id": "5s6pBESo1ybu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gradio interface"
      ],
      "metadata": {
        "id": "jw2FtW-ZH3Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cover_letter_tab = gr.Interface(\n",
        "    fn = cover_letter,\n",
        "    inputs = [gr.Textbox(label=\"Company Name*\"),\n",
        "              gr.Textbox(label=\"Job Title*\",\n",
        "                         placeholder=\"The job title you are going to apply goes here ...\"),\n",
        "              gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                         placeholder=\"Sepcial information about this company you want to include\"),\n",
        "              gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                         placeholder=\"Paste the job description here ...\"),\n",
        "              gr.File(file_types=[\".pdf\"])\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Feedbacks\", lines=50)\n",
        ")"
      ],
      "metadata": {
        "id": "lTuHS5HM1LUT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tab 4: Interview Question"
      ],
      "metadata": {
        "id": "2szdMvFb_Ci0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define interview_question function"
      ],
      "metadata": {
        "id": "JDaMSHtb_CZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interview_question_template = \"\"\"\n",
        "As an experienced interviewer for {role_title} at {company_name}, what are the\n",
        "likely {question_type} interview questions you would like to ask?\n",
        "\n",
        "Here is the job description: {role_description}\n",
        "Here is the company description: {company_description}\n",
        "\n",
        "Here are definitions for different types of interview questions:\n",
        "Understanding the differences between direct, behavioral, and technical interview questions is crucial for effective interview preparation. Each type serves a specific purpose in evaluating different aspects of a candidate's qualifications and suitability for a role.\n",
        "1. Direct Interview Questions:\n",
        "Purpose: These questions are straightforward and are designed to gather factual information about the candidate's background, qualifications, and work experience.\n",
        "Characteristics: Direct questions are usually clear-cut and require specific, concise answers. They don't typically require candidates to elaborate on scenarios or demonstrate problem-solving skills.\n",
        "2. Behavioral Interview Questions:\n",
        "Purpose: These questions are aimed at understanding how a candidate has behaved in specific situations in the past, based on the belief that past behavior is a good predictor of future behavior.\n",
        "Characteristics: Behavioral questions often start with phrases like \"Tell me about a time when...\" or \"Give me an example of...\". They require candidates to tell stories or anecdotes from their past experiences, demonstrating their skills, decision-making abilities, and how they handle work-related situations.\n",
        "3. Technical Interview Questions:\n",
        "Purpose: These questions assess the candidate's technical skills and knowledge pertinent to the specific role they are applying for. They are common in fields like IT, engineering, science, or any role that requires specific technical expertise.\n",
        "Characteristics: Technical questions are often quite specific and can include problem-solving or even practical demonstrations of skills. They may involve scenarios, hypothetical problems, coding tests, or detailed discussions of technologies or methodologies.\n",
        "Each type of question helps the interviewer gauge different aspects of a candidate's profile. Direct questions assess basic qualifications, behavioral questions evaluate soft skills and cultural fit, and technical questions measure job-specific skills and expertise.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kWYadf4WKX5o"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interview_question(comp_name, job_title, q_type, comp_info=\"\", job_des=\"\"):\n",
        "\n",
        "  #### Step 1: Create prompt ####\n",
        "  # 1. Define variables in prompt\n",
        "  input_var = [\"role_title\", \"company_name\", \"question_type\", \"role_description\",  \"company_description\"]\n",
        "\n",
        "  # 2. Define prompt template\n",
        "  template = interview_question_template\n",
        "\n",
        "  # 3. Create prompt template\n",
        "  prompt = PromptTemplate(\n",
        "    input_variables = input_var,\n",
        "    template = template\n",
        "  )\n",
        "  ###############################\n",
        "\n",
        "  #### Step 2: Read resume PDF to text ####\n",
        "  #extracted_resume = textract.process(your_resume.name, method='pdfminer')\n",
        "  #########################################\n",
        "\n",
        "  #### Step 3: Format prompt with user input ####\n",
        "  new_prompt = prompt.format(role_title=job_title,\n",
        "                             company_name=comp_name,\n",
        "                             question_type=q_type,\n",
        "                             role_description=job_des,\n",
        "                             company_description=comp_info)\n",
        "  ###############################################\n",
        "\n",
        "  #### Step4: Use chat model to answer the prompt ####\n",
        "  chat = ChatOpenAI(model_name = \"gpt-4\")\n",
        "  result = chat([HumanMessage(content=new_prompt)])\n",
        "  ####################################################\n",
        "\n",
        "  return result.content"
      ],
      "metadata": {
        "id": "F-sXLZ9xKXdQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gradio interface"
      ],
      "metadata": {
        "id": "pAh7kF3AKKFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interview_question_tab = gr.Interface(\n",
        "    fn = interview_question,\n",
        "    inputs = [gr.Textbox(label=\"Company Name*\"),\n",
        "              gr.Textbox(label=\"Job Title*\",\n",
        "                         placeholder=\"The job title you are going to apply goes here ...\"),\n",
        "              gr.Dropdown([\"Direct question\", \"Behavioral question\", \"Technical question\"],\n",
        "                          label=\"What type of interview questions you want to prepare?*\"),\n",
        "              gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                         placeholder=\"Sepcial information about this company you want to include\"),\n",
        "              gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                         placeholder=\"Paste the job description here ...\")\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Feedbacks\", lines=50)\n",
        ")"
      ],
      "metadata": {
        "id": "AKpD2-GnKYwo"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tab 5: Answer Evaluation"
      ],
      "metadata": {
        "id": "oLDcHDLP_CKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define answer_evaluation function"
      ],
      "metadata": {
        "id": "10IOEG84_B0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_evaluation_template = \"\"\"\n",
        "As an experienced career coach, you help students improve their skills for\n",
        "answering behavioral interview questions.  Please help this student improve the\n",
        "answer to the behavioral interview question {interview_questions} during the\n",
        "interview of {role_title} at {company_name}.\n",
        "\n",
        "The student’s answer: {question_answers}\n",
        "\n",
        "First, give the student's answer a score, and point by point feedback with rationale.\n",
        "Then, give your improved answer with a score and the rationale of why it is better.\n",
        "\n",
        "Here are job description and company backgroound that you might want to consider:\n",
        "Job Description: {role_description}\n",
        "Company Background: {company_description}\n",
        "\n",
        "Here are aspects that how interviewers should answer a behavioral interview question:\n",
        "When answering behavioral interview questions, it's essential to present your qualifications effectively by incorporating specific aspects that highlight your skills, experiences, and personal attributes. These aspects are crucial in demonstrating your suitability for the role and how well you align with the organization's values and culture. Here are key aspects to include:\n",
        "1.        Specific Examples: Use concrete examples from your past experiences to illustrate how you've handled situations relevant to the question. This provides tangible evidence of your skills and abilities.\n",
        "2.        STAR Method: Structure your response using the STAR method – Situation, Task, Action, and Result. This helps in organizing your answer clearly and concisely:\n",
        "•        Situation: Describe the context or background of the example you're using.\n",
        "•        Task: Explain the task or challenge you were facing.\n",
        "•        Action: Detail the specific actions you took to address the task or challenge.\n",
        "•        Result: Share the outcomes of your actions, highlighting your contributions and any lessons learned.\n",
        "3.        Relevance to the Role: Tailor your examples to demonstrate skills and attributes that are directly relevant to the job you're applying for. Show how your past experiences have prepared you for this specific role.\n",
        "4.        Problem-Solving Skills: Highlight your ability to identify problems, think critically, and implement effective solutions. Employers value candidates who can tackle challenges proactively.\n",
        "5.        Teamwork and Collaboration: Discuss how you work with others, emphasizing teamwork, communication, and interpersonal skills, especially if the role involves working closely with a team.\n",
        "6.        Adaptability and Flexibility: Show your ability to adapt to new situations, learn from experiences, and remain flexible in the face of change or uncertainty.\n",
        "7.        Leadership and Initiative: For roles that require leadership, illustrate your ability to lead, inspire, and motivate others. Even for non-leadership roles, showing initiative and the ability to take charge in appropriate situations can be beneficial.\n",
        "8.        Results and Impact: Focus on the results and impact of your actions. Quantify your achievements where possible, as this adds credibility and a sense of scale to your accomplishments.\n",
        "9.        Personal Development: Reflect on what you learned from the experience and how it contributed to your personal and professional growth.\n",
        "10.        Cultural Fit: Convey how your values, work ethic, and personality align with the company's culture. Show that you not only have the skills for the job but also would thrive in the organization's environment.\n",
        "Including these aspects in your behavioral interview responses can significantly strengthen your answers, showcasing your qualifications, experiences, and fit for the role.\n",
        "\n",
        "Here are aspects that companies hope to get from your answer of a behavioral question:\n",
        "Companies conduct behavioral interviews to assess various aspects of a candidate's past behavior, skills, and performance to predict their future behavior and suitability for the role in their organization. Here are some key elements that companies typically look for during behavioral interviews:\n",
        "1.        Past Performance as an Indicator of Future Behavior: Companies believe that past behavior is a good predictor of future behavior. By understanding how you handled situations in the past, they can gauge how you might perform in similar situations in their organization.\n",
        "2.        Problem-Solving and Decision-Making Skills: Employers look for candidates who can demonstrate effective problem-solving and decision-making skills. They are interested in how you approach challenges, analyze problems, and arrive at solutions.\n",
        "3.        Teamwork and Collaboration: Since most roles require some level of teamwork, companies want to see how well you work with others. Your ability to collaborate, communicate effectively, and contribute to a team is crucial.\n",
        "4.        Adaptability and Flexibility: With the fast pace of change in the workplace, companies seek candidates who can adapt to new situations and challenges quickly and effectively.\n",
        "5.        Leadership Qualities: For roles that involve leading others, employers look for leadership potential. This includes your ability to motivate, guide, and influence others, even if the role is not a traditional leadership position.\n",
        "6.        Work Ethic and Professionalism: Your approach to work, commitment to quality, and professional conduct are important to employers. They want to ensure you have a strong work ethic and can represent the company positively.\n",
        "7.        Cultural Fit: Companies are keen on finding candidates who will fit well with their organizational culture. This includes sharing similar values, work styles, and the ability to thrive in the company’s work environment.\n",
        "8.        Resilience and Stress Management: Employers may look for signs of resilience and your ability to handle stress or failure. They want employees who can remain productive and positive, even in challenging situations.\n",
        "9.        Communication Skills: Effective communication is key in any role. Companies assess your ability to articulate ideas clearly, listen to others, and communicate in a way that is effective and appropriate for the workplace.\n",
        "10.        Initiative and Self-motivation: Demonstrating that you are a self-starter who takes initiative is highly valued. Companies prefer candidates who show they can work independently and are motivated to achieve.\n",
        "In summary, behavioral interviews are designed to evaluate a candidate's suitability not only in terms of skills and experience but also in terms of their personality, work habits, and potential fit within the company's culture and team dynamics.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "f9G3ITz_KZf8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_evaluation(comp_name, job_title, inter_q, q_a=\"\", comp_info=\"\", job_des=\"\"):\n",
        "\n",
        "  #### Step 1: Create prompt ####\n",
        "  # 1. Define variables in prompt\n",
        "  input_var = [\"interview_questions\", \"role_title\", \"company_name\", \"question_answers\", \"role_description\",  \"company_description\"]\n",
        "\n",
        "  # 2. Define prompt template\n",
        "  template = answer_evaluation_template\n",
        "\n",
        "  # 3. Create prompt template\n",
        "  prompt = PromptTemplate(\n",
        "    input_variables = input_var,\n",
        "    template = template\n",
        "  )\n",
        "  ###############################\n",
        "\n",
        "  #### Step 2: Read resume PDF to text ####\n",
        "  #extracted_resume = textract.process(your_resume.name, method='pdfminer')\n",
        "  #########################################\n",
        "\n",
        "  #### Step 3: Format prompt with user input ####\n",
        "  new_prompt = prompt.format(interview_questions=inter_q,\n",
        "                             role_title=job_title,\n",
        "                             company_name=comp_name,\n",
        "                             question_answers=q_a,\n",
        "                             role_description=job_des,\n",
        "                             company_description=comp_info\n",
        "      )\n",
        "  ###############################################\n",
        "\n",
        "  #### Step4: Use chat model to answer the prompt ####\n",
        "  chat = ChatOpenAI(model_name = \"gpt-4\")\n",
        "  result = chat([HumanMessage(content=new_prompt)])\n",
        "  ####################################################\n",
        "\n",
        "  return result.content"
      ],
      "metadata": {
        "id": "HloqB6UOKZWP"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gradio interface"
      ],
      "metadata": {
        "id": "Y6yd76iVKVP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_evaluation_tab = gr.Interface(\n",
        "    fn = answer_evaluation,\n",
        "    inputs = [gr.Textbox(label=\"Company Name*\"),\n",
        "              gr.Textbox(label=\"Job Title*\",\n",
        "                         placeholder=\"The job title you are going to apply goes here ...\"),\n",
        "              gr.Textbox(label=\"Interview Question*\",\n",
        "                         placeholder=\"Paste the question you want to prepare here ...\"),\n",
        "              gr.Textbox(label=\"Your Answer\",\n",
        "                          placeholder=\"Type your answer for the interview question here ...\"),\n",
        "              gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                         placeholder=\"Sepcial information about this company you want to include\"),\n",
        "              gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                         placeholder=\"Paste the job description here ...\")\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Feedbacks\", lines=50)\n",
        ")"
      ],
      "metadata": {
        "id": "zi4DB-XkKaBz"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output in gradio"
      ],
      "metadata": {
        "id": "4e4pJIs6qZte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.TabbedInterface([api_tab,\n",
        "                           resume_review_tab,\n",
        "                           cover_letter_tab,\n",
        "                           interview_question_tab,\n",
        "                           answer_evaluation_tab],\n",
        "                            [\"OpenAI API Login\",\n",
        "                             \"Resume Review\",\n",
        "                             \"Cover Letter\",\n",
        "                             \"Interview Questions Generator\",\n",
        "                             \"Prepare Interview Question\"]\n",
        "                          )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "bGaTfDGN_n7z",
        "outputId": "9f01e1ea-0f10-41a6-cd42-b1b7f69d0b18"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://eccce148d7d08c7edd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eccce148d7d08c7edd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7864 <> https://eccce148d7d08c7edd.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEMOWYuPe_WN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
