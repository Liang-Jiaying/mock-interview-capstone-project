{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O7uN95EyvDPq",
        "8hD8hRVdqoQK",
        "NP3lGANUedyE",
        "1DFFQOtCevOM",
        "aVE23dUnb2A0",
        "eqI3Ka8yb6Xv",
        "lQcnJEIHb_pB",
        "J3m6fvEcps3d"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"Blue\">Abstract</font>\n",
        "\n",
        "In this notebook, we delve in using [Gradio](https://www.gradio.app/) to let people interact with our first draft of app.\n",
        "\n",
        "**<font color=\"red\">Our goal</font>** is to explore how to use Gradio and how to make our model work in graio.  \n",
        "\n",
        "We used following knowledge:  \n",
        "Useful links:\n",
        "1. [Gradio Playground](https://www.gradio.app/playground)\n",
        "2. [Gradio Docs](https://www.gradio.app/docs/interface)"
      ],
      "metadata": {
        "id": "H_ec5RQEu3yU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQDQBIguub4K",
        "outputId": "618137f5-1c2f-4938-8a7e-7b9cf75269dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.6.1 (from gradio)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.13)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=8c1b7cdd5295cd1db76925e107c5a7ebd872c4b167c224f0b76eb29d26ebe8d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.104.0 ffmpy-0.3.1 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.18.0 orjson-3.9.10 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 typing-extensions-4.8.0 uvicorn-0.23.2 websockets-11.0.3\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.18.0\n",
            "    Uninstalling huggingface-hub-0.18.0:\n",
            "      Successfully uninstalled huggingface-hub-0.18.0\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install transformers\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example"
      ],
      "metadata": {
        "id": "O7uN95EyvDPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Zp3nJmGWu05a",
        "outputId": "c0fcc38a-2bbd-48c1-da26-4679427cdff5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://bb722ad3fd50cc65a8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bb722ad3fd50cc65a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1"
      ],
      "metadata": {
        "id": "6YVOGrfW4axT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set layout"
      ],
      "metadata": {
        "id": "8hD8hRVdqoQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import PlaceHolder\n",
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        text1_1 = gr.Textbox(label=\"Company Name*\")\n",
        "        text1_2 = gr.Textbox(label=\"Job Title*\",\n",
        "                           placeholder=\"The job title you are going to apply goes here ...\")\n",
        "        drop1_3 = gr.Dropdown([\"Job Recruiter\", \"HR Manager\", \"Hiring Manager\",\n",
        "                             \"Executives\", \"Potential Coworkers\"],\n",
        "                            label=\"Who do you want to interview with?*\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "          text2_1 = gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                               placeholder=\"Sepcial information about this company you want to include\")\n",
        "          text2_2 = gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                               placeholder=\"Paste the job description here ...\")\n",
        "          text2_3 = gr.Textbox(label=\"Interviewer's LinkedIn URL (Optional)\",\n",
        "                               placeholder=\"Paste the URL here ...\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "          with gr.Tab(\"Your Resume*\"):\n",
        "            file4_1 = gr.File(file_types=[\".pdf\"])\n",
        "          with gr.Tab(\"Cover Letter\"):\n",
        "            file4_2 = gr.File(file_types=[\".pdf\"])\n",
        "          btn = gr.Button(\"Resume Review\")\n",
        "    with gr.Row():\n",
        "        textout = gr.Textbox(label=\"Feedbacks for your resume\")"
      ],
      "metadata": {
        "id": "RAM_OJJLu2qc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output in gradio"
      ],
      "metadata": {
        "id": "kOzODPoQqj_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "4nQANf91u2mx",
        "outputId": "b03eb5c0-d267-4272-9c2e-0295dd5cabfe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8affdb01d792b5af36.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8affdb01d792b5af36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2"
      ],
      "metadata": {
        "id": "R66cJTw-S_1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup packages and API key"
      ],
      "metadata": {
        "id": "NP3lGANUedyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download required packages to Colab\n",
        "\n",
        "!pip install -q langchain\n",
        "!pip install -q openai\n",
        "!pip install -q chromadb\n",
        "!pip install -q tiktoken\n",
        "!pip install -q duckduckgo-search\n",
        "\n",
        "# 2. Import packages\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, RetrievalQA\n",
        "from langchain import ConversationChain\n",
        "from langchain.agents import load_tools, initialize_agent, AgentType\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "import textract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdaI2hDNYfLb",
        "outputId": "5490404d-2e47-46df-c9ab-f35d2a97bc6b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Setup OpenAI API key\n",
        "\n",
        "openai_api_key = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9jZqQhgYLDr",
        "outputId": "a0f4f602-76fb-495c-82a4-a82e9f44df5a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define resume_review function"
      ],
      "metadata": {
        "id": "1DFFQOtCevOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_review(comp_name, job_title, interviewer_title,\n",
        "                  comp_info=\"\", job_des=\"\", interviewer_url=\"\",\n",
        "                  your_resume=\"\"):\n",
        "\n",
        "  #### Step 1: Create prompt ####\n",
        "  # 1. Define variables in prompt\n",
        "  input_var = [\"interviewer_role\", \"company_name\", \"resume\", \"role_title\", \"role_description\", \"company_description\"]\n",
        "\n",
        "  # 2. Define prompt template\n",
        "  template = \"\"\"\n",
        "  You are a {interviewer_role}, for {company_name}. Please review the following resume {resume}.\n",
        "  For the role of {role_title}.\n",
        "  (optional: Here is the job description: {role_description})\n",
        "  (optional: Here is a description of the company: {company_description})\n",
        "  Give point by point feedback with rationale and suggested edits.\n",
        "  \"\"\"\n",
        "\n",
        "  # 3. Create prompt template\n",
        "  prompt = PromptTemplate(\n",
        "    input_variables = input_var,\n",
        "    template = template\n",
        "  )\n",
        "  ###############################\n",
        "\n",
        "  #### Step 2: Read resume PDF to text ####\n",
        "  extracted_resume = textract.process(your_resume.name, method='pdfminer')\n",
        "  #########################################\n",
        "\n",
        "  #### Step 3: Format prompt with user input ####\n",
        "  new_prompt = prompt.format(interviewer_role=interviewer_title,\n",
        "                            company_name=comp_name,\n",
        "                            resume=extracted_resume,\n",
        "                            role_title=job_title,\n",
        "                            role_description=job_des,\n",
        "                            company_description=comp_info)\n",
        "  ###############################################\n",
        "\n",
        "  #### Step4: Use chat model to answer the prompt ####\n",
        "  chat = ChatOpenAI(model_name = \"gpt-4\")\n",
        "  result = chat([HumanMessage(content=new_prompt)])\n",
        "  ####################################################\n",
        "\n",
        "  return result.content"
      ],
      "metadata": {
        "id": "illWu24zu2j7"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo2 = gr.Interface(\n",
        "    fn = resume_review,\n",
        "    inputs = [gr.Textbox(label=\"Company Name*\"),\n",
        "              gr.Textbox(label=\"Job Title*\",\n",
        "                         placeholder=\"The job title you are going to apply goes here ...\"),\n",
        "              gr.Dropdown([\"Job Recruiter\", \"HR Manager\", \"Hiring Manager\", \"Executives\", \"Potential Coworkers\"],\n",
        "                          label=\"Who do you want to interview with?*\"),\n",
        "              gr.Textbox(label=\"Company Info (Optional)\",\n",
        "                         placeholder=\"Sepcial information about this company you want to include\"),\n",
        "              gr.Textbox(label=\"Job Description (Optional)\",\n",
        "                         placeholder=\"Paste the job description here ...\"),\n",
        "              gr.Textbox(label=\"Interviewer's LinkedIn URL (Optional)\",\n",
        "                         placeholder=\"Paste the URL here ...\"),\n",
        "              gr.File(file_types=[\".pdf\"])\n",
        "    ],\n",
        "    outputs = gr.Textbox(label=\"Feedbacks\", lines=50))"
      ],
      "metadata": {
        "id": "GUpqBLnru2dc"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output in gradio"
      ],
      "metadata": {
        "id": "4e4pJIs6qZte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo2.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "ITLM2SF1jxLH",
        "outputId": "6945071e-f87b-41c7-9ee1-224c4dd37c53"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://7917f84a355f678e50.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7917f84a355f678e50.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7880 <> https://7917f84a355f678e50.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEMOWYuPe_WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "8diq2KQGbyaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare different PDF reader"
      ],
      "metadata": {
        "id": "aVE23dUnb2A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyPDF2 (not getting format)"
      ],
      "metadata": {
        "id": "eqI3Ka8yb6Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "\n",
        "import PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJdoylTpZhuf",
        "outputId": "c21c5f64-385f-4883-cce4-0810a81e6ddd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader = PyPDF2.PdfReader('drive/MyDrive/sample_resume.pdf')"
      ],
      "metadata": {
        "id": "UbEu7zYoX4iR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader.pages[0].extract_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "qP_X9WGBXdmZ",
        "outputId": "427c08bb-6c23-4d34-d4bf-567673cccd43"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"EDUCATION \\n EXPERIENCE Washington University School of Medicine – Institute for Informatics Data Science Intern, Advisor: Dr. Ruijin Lu      St. Louis, MO May 2023 – Aug. 2023 North American Prodromal Synucleinopathy (NAPS) Project \\x9f Data Quality Control Automating: Implemented Python-based automation, reducing document download time by 99.2%, equivalent to saving a full week's work for one individual. Minimized manual & repetitive tasks, enhancing project efficiency by improving data quality, and aiding the group in identifying Alzheimer's Disease biomarkers across ten US sites. \\x9f Database & Data Management: Leveraged Python and Rave to optimize database updates, achieved a 75% time reduction updating birth records. Integrated with Amazon Textract API to halve the time of handwritten text extraction, enhanced overall efficiency, accuracy, and expanded system scalability. Minimized human bias through automated handwritten text recognition. \\x9f Collaboration & Problem Solving: Collaborated with data coordinators to proactively identify and address API integration and data accessibility issues, ensuring seamless data flow and enhanced system functionality. Contributed feedback to improve the quality of approximately 100 source documents, ensuring subsequent users access more refined and reliable data.  PROJECTS Mock Interview Practice Application – Capstone Project Project Designer & Project Manager & Code Contributor, Advisor: Dr. Jesse Spencer-Smith Nashville, TN Aug. 2023 – Present Project Overview: Develop a Mock Interview Practice Application aim at motivating and helping current and future students at Data Science Institute prepare for job interviews by providing a platform where they can practice interview questions and receive feedback. The project involves designing the application architecture, managing the project timeline, and actively contributing to the codebase. Roles and Responsibilities: \\x9f Project Designer: Conceptualize and design the application based on users’ needs and career coaches’ insights, ensuring a user-friendly interface and seamless navigation. Collaborated with team members to refine the project scope and objectives. \\x9f Project Manager: Oversaw the project timeline and coordinated team efforts to ensure timely completion. Implemented agile project management methodologies to facilitate effective collaboration and iterative development. \\x9f Code Contributor: Contributed to the development of the application by writing and reviewing code. Applied data science techniques to analyze user data and provide personalized feedback to users based on their performance.  Insurance Claims Prediction for Asurion – Data Science Teams Course Data Science Candidate, Instructor: Dana Zhang Nashville, TN Jan. 2023 – May 2023 Project Overview: Developed a market applicable forecasting model using Python to predict iPhone 14 claim volume for each week of March 2023 for a phone insurance company. Worked in a four persons team, followed agile workflow and data science project flow. Roles and Responsibilities: \\x9f Data Collection & Cleaning: Collected and cleaned weather, Apple shipment, stock and iPhone release date. Feature engineered seasonal promotion. Combined outside source data with Asurion’s phone claim data before March 2023. \\x9f Data Analysis & Modeling: Explored different visualizations for different phone brands, phone models, phone colors, and phone’s storage sizes to get insight about data. Developed basic regression models, time series models, and ensemble models. \\x9f Collaboration & Teamwork: Played both team leader role and team player role. Improved productivity of teamwork by updating, communicating and discussing constantly about each teammate’s progresses, challenges, findings, and team health. \\x9f Stakeholder Engagement & Presentation: Presented stakeholder results by transferring predicted numbers to estimated market value. Communicated with stakeholder the insights of advantages of overpredicting in the early stage of the device life cycle.  ADDITIONAL INFORMATION Programming Skills: Python (Numpy, Pandas, Seaborn, Scikit-learn, PyTorch, Matplotlib), SQL (MySQLWorkbench, Database Design), NLP (Transformers, HuggingFace, LLMs, Prompt Engineering, LangChain), R (Statistical Analysis, Shiny) Deliverable Skills: GitHub flow (Version Control, Project Board, Agile Project Management), Microsoft PowerPoint Learning: Amazon Web Services (AWS), Google Cloud Platform (GCP), Tableau Vanderbilt University – Data Science Institute Master of Science in Data Science Nashville, TN May 2024 \\x9f Anticipated Coursework: Transformers in Theory and Practice, Data Science Algorithms, Launching the Venture \\x9f Relevant Coursework: EDA, Data Science Applications in Industry, Data Management Systems (SQL), Machine Learning  \\x9f Cumulative GPA: 3.89/4.0 Saint Louis University Bachelor of Science in Data Science & Mathematics, Minor in Computer Science St. Louis, MO        May 2022 \\x9f Relevant Coursework: Applied Regression, Applied Topology, Time Series, R for Spatial Analysis, Bayesian Statistics \\x9f Cumulative GPA: 3.9/4.0 (Dean’s List for 8 semesters) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### textract (get the format, but a lot format sign)"
      ],
      "metadata": {
        "id": "lQcnJEIHb_pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textract\n",
        "\n",
        "import textract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aZqjLqw7bPTX",
        "outputId": "658971da-0f94-486c-9d93-32f2b82afc67"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting argcomplete~=1.10.0 (from textract)\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0 (from textract)\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.* (from textract)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt~=0.8 (from textract)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting extract-msg<=0.29.* (from textract)\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20191110 (from textract)\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-pptx~=0.6.18 (from textract)\n",
            "  Downloading python_pptx-0.6.22-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.12.0 (from textract)\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1 (from textract)\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xlrd~=1.2.0 (from textract)\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from pdfminer.six==20191110->textract)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Collecting imapclient==2.1.0 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.2)\n",
            "Collecting compressed-rtf>=1.0.6 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ebcdic>=1.1.1 (from extract-msg<=0.29.*->textract)\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.3)\n",
            "Requirement already satisfied: Pillow<=9.5.0,>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx~=0.6.18->textract)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=fdd4ee7e5eb17cf7f770d7cc47a041886a210484ae730ca994b5cc313c1061fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6185 sha256=2c6cdb1b0914466bfd8a95df989f4dba411860b2599aaba2898298bb756f450a\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/3e/48/e7d833ecc516c36f8966d310b1a6386db091a718f1ff3bf85c\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=02eef425ce421844b0a68f3124f401890629a588a4ffaba4141bf9a5facdd023\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built docx2txt compressed-rtf olefile\n",
            "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, XlsxWriter, xlrd, six, pycryptodome, olefile, beautifulsoup4, python-pptx, pdfminer.six, imapclient, extract-msg, textract\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 2.0.1\n",
            "    Uninstalling xlrd-2.0.1:\n",
            "      Successfully uninstalled xlrd-2.0.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "pydrive2 1.6.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "yfinance 0.2.31 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SpeechRecognition-3.8.1 XlsxWriter-3.1.9 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.19.0 python-pptx-0.6.22 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = textract.process('drive/MyDrive/sample_resume.pdf', method='pdfminer')"
      ],
      "metadata": {
        "id": "HamduOGebPQv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "xhO8rJeXbPGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test how to extract text from PDF in gradio.File()"
      ],
      "metadata": {
        "id": "J3m6fvEcps3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define test_read_pdf"
      ],
      "metadata": {
        "id": "DiqfPThdp_W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_read_pdf(resume_dir):\n",
        "  text = textract.process(resume_dir.name)\n",
        "  return(text)"
      ],
      "metadata": {
        "id": "-d1r0xVge_go"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test whether it works in gradio"
      ],
      "metadata": {
        "id": "jB_oYM2tqKTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_demo = gr.Interface(\n",
        "    fn = test_read_pdf,\n",
        "    inputs = gr.File(file_types=[\".pdf\"]),\n",
        "    outputs = gr.Textbox(label=\"resume\")\n",
        ")\n",
        "\n",
        "test_demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Gx7RSH8We_eB",
        "outputId": "1bca9890-bf21-443c-f466-0f20394d16c0"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://ec9148c7e8ea6a6e2c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ec9148c7e8ea6a6e2c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7880 <> https://ec9148c7e8ea6a6e2c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcbmF4sydAuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}